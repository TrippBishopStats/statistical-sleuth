---
title: "Chapter 2" 
author: "Tripp Bishop" 
format: html
---
```{r setup}
#| echo: false
rm(list = ls())
library(tidyverse)
library(tidymodels)
```
We first create a dataframe to store our data.
```{r sparrow data}
survived <- rep(c(TRUE, FALSE), times=c(35,24))
humerus_length_in <- c(
  #survivors
  0.687,0.703,0.709,0.715,0.721,0.723,0.723,0.726,0.728,0.728,0.728,
  0.729,0.730,0.730,0.733,0.733,0.735,0.736,0.739,0.741,0.741,0.741,
  0.741,0.743,0.749,0.751,0.752,0.752,0.755,0.756,0.766,0.767,0.769,
  0.770,0.780,
  # victims
  0.659,0.689,0.702,0.703,0.709,0.713,0.720,0.720,0.726,0.726,0.729,
  0.731,0.736,0.737,0.738,0.738,0.739,0.743,0.744,0.745,0.752,0.752,
  0.754,0.765
)
df_sparrows <- tibble(humerus_length_in, survived) |>
  mutate(
    survived = factor(survived, labels = c("Perished", "Survived"))
  )
```
Since we have already collected and stored the data, the next step is to
calculate the test statistic. Here, we're interested in the difference in means
of the length of the humerus bone in the two groups of sparrows.
```{r create test statistic}
obs_diff <- df_sparrows |>
  specify(humerus_length_in ~ survived) |>
  calculate(stat = "diff in means", order = c("Survived", "Perished")) |>
  pull()
```
Now, we create a `null world` where we create a sampling distribution where the
survival of the individual birds is independent of their humerus length.
```{r creat null distribution}
sparrows_null <- df_sparrows |>
  specify(humerus_length_in ~ survived) |>
  hypothesise(null = "independence") |>
  generate(reps = 1500, type = "permute") |>
  calculate(stat = "diff in means", order = c("Survived", "Perished"))
p_value <- round(
  get_p_value(sparrows_null, obs_stat = obs_diff, direction = "both"),
  4
)
visualise(sparrows_null) +
  shade_p_value(obs_diff, direction = "both") +
  annotate("text", label = paste("p-value = ", p_value, sep=""), x = 0.014, y=150)
```
```{r t-test manual}
sd_died <- df_sparrows |>
  filter(survived == "Perished") |>
  summarise(
    std_dev = sd(humerus_length_in)
  ) |>
  pull()
sd_lived <- df_sparrows |>
  filter(survived == "Survived") |>
  summarise(
    std_dev = sd(humerus_length_in)
  ) |>
  pull()
pooled_sd <- sqrt((sd_died^2*23 + sd_lived^2*34)/57)
SE <- pooled_sd*sqrt(1/24 + 1/35)
t_stat <- obs_diff/(SE)
df <- 24 + 35 -2
p_value <- pt(t_stat, df, lower.tail = FALSE)
two_sided <- p_value*2
qt(0.025, 57)
qt(0.975, 57)
```
## Conceptual Exercises

### Problem 1
> In drawing conclusions about the Bumpus data , why might it be important to 
know whether all the birds were measured before the ones htat perished actually 
died?

If the birds' bodies change after death, this could distort the group
differences. It might be possible that the death of the birds is what is causing
a difference in mean humerus length.

There is also the possibility of measurement bias since the researcher measuring
the birds will know which ones are dead and alive and if they have a particular 
expectation it might result in them subtly changing the way that they make their
measurements of the individual specimens.

### Problem 2
> For comparing two population means when the population distributions have the 
same standard deviation, the standard deviation is sometimes referred to as a
nuisance parameter. Explain why it might be considered a nuisance.

The standard deviation is not generally of that much interest, but it must be
estimated from the data, because it is not usually known, in order to 
investigate the mean.

### Problem 3
>True or false? If the sample size is large, then the shape of the histogram of
the sample will be approximately normal, even if the population distribution is
not normal.

This is false. The histogram of the sample will approximate the population 
distribution. The larger the sample, the better the approximation of this
distribution.

### Problem 4
> True or false? If a sample size is large, then the shapre of the sampling
distribution will be approximately normal, even if the population distribution
is not normal.

This is true. This is the result of the central limit theorem. In particular,
the standard error of the sampling distribution will get smaller and tails of
the distribution will shrink.

### Problem 5
> Explain the relative merits of 90% and 99% levels of confidence.

The level of confidence is directly related to the width of the interval. A 
lower level of confidence results in a narrower interval which might provide
better constraint on the true value of the parameter, but you risk being wrong
in your estimate of the parameter and therefore the outcome of your hypothesis
test. You risk rejecting the null hypothesis when you should not. This is known
as a Type II error.

On the other hand, a high confidence level means that you are likely to capture
the true value of the parameter, but you are more likely to fail to reject the 
null hypothesis even though it is false. This is known as a Type I error.

The choice of confidence level is often governed by the penalty paid for making
a  Type I or II error. If a false possible would be a bad outcome, then a higher
confidence level is warranted. Perhaps you want to be very certain that you have
detected something real, in which case you would want to set $\alpha$ quite
small. On the other hand, if you want to avoid false negatives, a narrower
confidence interval will likely result in rejecting the null hypothesis.

### Problem 6
> What is wrong with the hypothesis that $\bar{Y}_2 - \bar{Y}_1 = 0$?

The hypothesis is about the population means $\mu_1, \mu_2$ not the sample 
means.

Kinda pedantic... but whatever.

### Problem 7
> In a study of the effects of marijuana use during pregnancy, measurements on 
babies of mothers who used marijuana during pregnancy were compared to 
measurements on babies of mothers who did not. A 95% confidence interval for the
difference in mean head circumference (nonuse minus use) was 0.61 to 1.19cm. 
What can be said from this statement about a *p*-value for the hypothesis that 
the mean difference is zero?

Since the interval does not contain zero, we know that the *p*-value is going to
be small. Since the confidence interval is $100(1-\alpha) = 95%$, we know that 
our threshold is $p=0.05$. We know that $p < 0.05$ given that the interval does 
not contain the hypothesised parameter value. 

### Problem 8
> Suppose the following statement is made in a statistical summary: "A 
comparison of breathing capacities of individuals in househols with low nitrogen
dioxide levels and individuals in households with high nitrogen dioxide levels 
indicated that there is not difference in the means 
(two-sided, *p*-value=0.24)". What is wrong with this statement?

The statement is too strong. When performing a hypothesis test, the null
hypothesis is not accepted, we simply fail to reject it. Stated another way, the
data collected are not consistent with the means being different, but that
doesn't rule out future data being incompatible with unequal means.

### Problem 9
> What is the difference (a) between the mean of $Y$ and the mean of $\bar{Y}$?
(b) the standard deviation of $Y$ and the standard deviation of $\bar{Y}$?(c) 
the standard deviation of $\bar{Y}$ and the standard error of $\bar{Y}$?(d) a 
t-ratio and a t-statistic?

(a) The mean of $Y$ is the population mean and as the mean of $\bar{Y}$ is the 
mean of the sampling distribution. In the limit as the sample size ($n$) goes to
infinite, the two values are equal.
(b) The standard deviation of the population ($Y$) is $\sigma$. The standard 
deviation of the sampling distribution is $\sigma/\sqrt{n}$. Notice that as 
$n \rightarrow \infty$ that the standard deviation of the sampling distribution
goes to zero, indicating that the population mean and the mean of the sampling
distribution converge.
(c) The standard deviation of $\bar{Y}$ and the standard error of $\bar{Y}$ are
the same thing. The standard error is called that because it tells us our best
guess about $\bar{Y} - \mu$. In other words, it's our best guess about how
far from the true mean our sample mean is.
(d) The t-ratio is the ratio of the error of the sample mean from the population
mean to the standard error of the sampling distribution. The t-ratio relates the
possible values of the population mean to a t-distribution with the appropriate
degrees of freedom based on the sample size. The t-statistic, on the other hand, 
is the ratio of the difference of means of two samples 
(of different populations) to a hypothesised difference in their population means
(typically taken to be zero) to the pooled standard error of the two samples.

*Addendum* - The t-ratio is generally not know because we don't actually know 
the population parameter. The t-statistic is a trial value of the t-ratio where
we use a hypothsised value of the parameter which we are testing with the NHST
framework.

### Problem 10
> Consider blood pressure levels for populations of young women using birth
control pills and young women not using birth control pills. A comparison of 
these populations through an observational study might be consisten with the 
theory that the pill elevates blood pressure levels. What tool is appropriate 
for addressing whether there is a difference between these two population? What 
tool is appropriate for addressing the likely size of the difference?

*p*-values are one way to access how likely it is that we would observe a 
difference equal to or more extreme than our data assuming that the null 
hypothesis of no difference is true.

A confidence interval constructed using the NHST framework will tell us what
percentage of sample means will fall within the range given by the confidence
interval. It is important to note that it doesn't say anything about whether our
data falls within this range. It is very easy to misinterpret frequentist
confidence intervals.

### Problem 11
> The data in Display 2.14 are survival times (in days) of guinea pigs that were
randomly assigned either to a control group or ato a treatment group that 
received a dose of tubercle bacilli. (a) Why might the additive treatment effect
model be inappropriate for these data? (b) Why might the ideal normal model with
equal spread be an inadequate approximation?



## Computational Exercises


## Data Exercises